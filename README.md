# Web-Science Coursework (H)

Partition Data should be used to run a quick analysis on the code. The Enhanced Crawler can be used but may take quite long to run

The access keys and tokens need to be populated with the Twitter API keys you have.

Task 1a.py - Twitter streaming to collect 1% of the data

Task 1b.py - Enhanced crawler by querying trends

Task 2.py - Groups the data into clusters and produces the graph of each cluster with statistics.

Task 3 and 4.py - Graph of user interactions and triads

## Installation 

The following libraries need to be installed for the program to run:

NetworkX

Tweepy

Pymongo

Seaborn

Numpy

Scikit-Learn

Matplotlib

Pandas

Datetime

JGraph

Scipy

